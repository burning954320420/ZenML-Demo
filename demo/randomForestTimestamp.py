import os
import pandas as pd
import numpy as np
from datetime import datetime
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from zenml import pipeline, step
from zenml.logger import get_logger

# åˆ›å»º logger
logger = get_logger(__name__)

# ------------------ æ­¥éª¤ 1: åŠ è½½æ•°æ® ------------------
@step
def load_data(data_path: str) -> pd.DataFrame:
    """åŠ è½½å¸¦ Unix æ—¶é—´æˆ³çš„ CPU æ•°æ®"""
    try:
        df = pd.read_csv(data_path)
        logger.info(f"âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•")
        return df
    except Exception as e:
        logger.error(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
        raise

# ------------------ æ­¥éª¤ 2: ç‰¹å¾å·¥ç¨‹ - æå–æ—¶é—´ç‰¹å¾ ------------------
@step
def feature_engineering(df: pd.DataFrame) -> tuple[np.ndarray, np.ndarray]:
    """è§£æ Unix æ—¶é—´æˆ³ï¼Œæå–æ—¶é—´ç‰¹å¾ï¼Œå¹¶ç»„åˆ cpu_usage è¿›è¡Œè®­ç»ƒ"""
    required_columns = ['timestamp', 'cpu_usage', 'is_normal']
    if not all(col in df.columns for col in required_columns):
        raise ValueError(f"CSV æ–‡ä»¶å¿…é¡»åŒ…å«åˆ—: {required_columns}")

    # è§£æ Unix æ—¶é—´æˆ³
    df['datetime'] = pd.to_datetime(df['timestamp'], unit='s')  # å‡è®¾æ—¶é—´æˆ³ä¸ºç§’çº§

    # æå–æ—¶é—´ç‰¹å¾
    df['hour'] = df['datetime'].dt.hour                    # å°æ—¶ (0-23)
    df['weekday'] = df['datetime'].dt.weekday              # æ˜ŸæœŸå‡  (0=å‘¨ä¸€, 6=å‘¨æ—¥)
    df['is_weekend'] = (df['datetime'].dt.weekday >= 5).astype(int)  # æ˜¯å¦å‘¨æœ«
    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)    # å‘¨æœŸæ€§ç¼–ç ï¼šsin
    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)    # å‘¨æœŸæ€§ç¼–ç ï¼šcos

    # ç‰¹å¾åˆ—
    feature_columns = [
        'cpu_usage',
        'hour',
        'weekday',
        'is_weekend',
        'hour_sin',
        'hour_cos'
    ]

    X = df[feature_columns].values
    y = df['is_normal'].values

    logger.info(f"ğŸ“Š ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {X.shape}")
    logger.info(f"ğŸ·ï¸  æ ‡ç­¾å‘é‡å½¢çŠ¶: {y.shape}")
    logger.info(f"ğŸ§© ä½¿ç”¨çš„ç‰¹å¾: {feature_columns}")

    return X, y

# ------------------ æ­¥éª¤ 3: è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹ ------------------
@step
def train_random_forest(X: np.ndarray, y: np.ndarray) -> RandomForestClassifier:
    """ä½¿ç”¨åŒ…å«æ—¶é—´ç‰¹å¾çš„éšæœºæ£®æ—æ¨¡å‹"""
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=7,
        random_state=42,
        n_jobs=-1
    )
    model.fit(X_train, y_train)

    # è¯„ä¼°
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    logger.info(f"ğŸ“ˆ æµ‹è¯•é›†å‡†ç¡®ç‡: {acc:.4f}")

    logger.info("ğŸ“‹ åˆ†ç±»æŠ¥å‘Š:")
    logger.info("\n" + classification_report(y_test, y_pred, target_names=["æ­£å¸¸ (0)", "å¼‚å¸¸ (1)"]))

    return model

# ------------------ æ­¥éª¤ 4: ä¿å­˜æ¨¡å‹ ------------------
@step
def save_model(model: RandomForestClassifier, save_path: str = "cpu_anomaly_detector_with_unix_time.pkl"):
    """ä¿å­˜æ¨¡å‹"""
    import joblib
    joblib.dump(model, save_path)
    model_path = os.path.abspath(save_path)
    logger.info(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜è‡³: {model_path}")
    return model_path

# ------------------ å®šä¹‰ ZenML Pipeline ------------------
@pipeline
def cpu_training_pipeline_with_unix_time(data_path: str, model_save_path: str):
    """åŒ…å«æ—¶é—´ç‰¹å¾çš„ CPU å¼‚å¸¸æ£€æµ‹ç®¡é“ï¼ˆUnix æ—¶é—´æˆ³ç‰ˆæœ¬ï¼‰"""
    df = load_data(data_path)
    X, y = feature_engineering(df)
    model = train_random_forest(X, y)
    save_model(model, model_save_path)

# ------------------ ä¸»å‡½æ•° ------------------
if __name__ == "__main__":
    DATA_PATH = "../data/cpu_data_timestamp.csv"
    MODEL_SAVE_PATH = "../models/cpu_anomaly_detector_with_unix_time.pkl"

    if not os.path.exists(DATA_PATH):
        raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {os.path.abspath(DATA_PATH)}")

    # è¿è¡Œç®¡é“
    cpu_training_pipeline_with_unix_time(
        data_path=DATA_PATH,
        model_save_path=MODEL_SAVE_PATH
    )

    print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼æ¨¡å‹å·²ä¿å­˜è‡³: {os.path.abspath(MODEL_SAVE_PATH)}")
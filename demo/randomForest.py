import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from zenml import pipeline, step
from zenml.logger import get_logger

# åˆ›å»º loggerï¼ˆå¿…é¡»ä¼ å‚ï¼‰
logger = get_logger(__name__)

# ------------------ æ­¥éª¤ 1: åŠ è½½æ•°æ® ------------------
@step
def load_data(data_path: str) -> pd.DataFrame:
    """åŠ è½½ CPU æ•°æ® CSV æ–‡ä»¶"""
    try:
        df = pd.read_csv(data_path)
        logger.info(f"âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•")
        return df
    except Exception as e:
        logger.error(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
        raise

# ------------------ æ­¥éª¤ 2: é¢„å¤„ç†æ•°æ® ------------------
@step
def preprocess_data(df: pd.DataFrame) -> tuple[np.ndarray, np.ndarray]:
    """æå– cpu_usage ä½œä¸ºç‰¹å¾ï¼Œis_normal ä½œä¸ºæ ‡ç­¾"""
    required_columns = ['cpu_usage', 'is_normal']
    if not all(col in df.columns for col in required_columns):
        raise ValueError(f"CSV æ–‡ä»¶å¿…é¡»åŒ…å«åˆ—: {required_columns}")

    X = df[['cpu_usage']].values           # ç‰¹å¾ï¼šCPU ä½¿ç”¨ç‡ï¼ˆäºŒç»´æ•°ç»„ï¼‰
    y = df['is_normal'].values             # æ ‡ç­¾ï¼š0=æ­£å¸¸ï¼Œ1=å¼‚å¸¸

    logger.info(f"ğŸ“Š ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {X.shape}")
    logger.info(f"ğŸ·ï¸  æ ‡ç­¾å‘é‡å½¢çŠ¶: {y.shape}")

    return X, y

# ------------------ æ­¥éª¤ 3: è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹ ------------------
@step
def train_random_forest(X: np.ndarray, y: np.ndarray) -> RandomForestClassifier:
    """ä½¿ç”¨éšæœºæ£®æ—è®­ç»ƒå¼‚å¸¸æ£€æµ‹æ¨¡å‹"""
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    # ä½¿ç”¨éšæœºæ£®æ—åˆ†ç±»å™¨
    model = RandomForestClassifier(
        n_estimators=100,      # 100 æ£µæ ‘
        max_depth=5,           # æ§åˆ¶è¿‡æ‹Ÿåˆ
        random_state=42,
        n_jobs=-1              # ä½¿ç”¨æ‰€æœ‰ CPU æ ¸å¿ƒ
    )
    model.fit(X_train, y_train)

    # è¯„ä¼°
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    logger.info(f"ğŸ“ˆ æµ‹è¯•é›†å‡†ç¡®ç‡: {acc:.4f}")

    logger.info("ğŸ“‹ åˆ†ç±»æŠ¥å‘Š:")
    logger.info("\n" + classification_report(y_test, y_pred, target_names=["æ­£å¸¸ (0)", "å¼‚å¸¸ (1)"]))

    logger.info("ğŸ“Š æ··æ·†çŸ©é˜µ:")
    logger.info("\n" + str(confusion_matrix(y_test, y_pred)))

    return model

# ------------------ æ­¥éª¤ 4: ä¿å­˜æ¨¡å‹ ------------------
@step
def save_model(model: RandomForestClassifier, save_path: str = "cpu_anomaly_detector.pkl"):
    """å°†è®­ç»ƒå¥½çš„æ¨¡å‹ä¿å­˜åˆ°æœ¬åœ°"""
    import joblib
    joblib.dump(model, save_path)
    model_path = os.path.abspath(save_path)
    logger.info(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜è‡³: {model_path}")
    return model_path

# ------------------ å®šä¹‰ ZenML Pipeline ------------------
@pipeline
def cpu_training_pipeline(data_path: str, model_save_path: str):
    """åŸºäºéšæœºæ£®æ—çš„ CPU å¼‚å¸¸æ£€æµ‹è®­ç»ƒæµç¨‹"""
    df = load_data(data_path)
    X, y = preprocess_data(df)
    model = train_random_forest(X, y)
    save_model(model, model_save_path)

# ------------------ ä¸»å‡½æ•° ------------------
if __name__ == "__main__":
    DATA_PATH = "data/cpu_data.csv"              # æ•°æ®æ–‡ä»¶è·¯å¾„
    MODEL_SAVE_PATH = "cpu_anomaly_detector.pkl" # æ¨¡å‹ä¿å­˜è·¯å¾„

    # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(DATA_PATH):
        raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {os.path.abspath(DATA_PATH)}")

    # è¿è¡Œ ZenML ç®¡é“
    cpu_training_pipeline(
        data_path=DATA_PATH,
        model_save_path=MODEL_SAVE_PATH
    )

    print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼éšæœºæ£®æ—æ¨¡å‹å·²ä¿å­˜è‡³: {os.path.abspath(MODEL_SAVE_PATH)}")